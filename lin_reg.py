# -*- coding: utf-8 -*-
"""Задание: Линейная регрессия.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ifwJ2J5rjZyzqWF5YzYaDZc4fBGq0d7Q

# Задание: Линейная регрессия
Задание: https://github.com/ivtipm/ML/blob/main/plans/AI_intro_2025/2025_ML_intro.md

# 1. Генерация синтетических данных
"""

from sklearn.datasets import make_regression
import pandas as pd

X, y = make_regression( n_samples=500, n_features=4, n_informative=2, noise=10.0, coef=True, random_state=212862 )

data0 = pd.DataFrame( {'x1': X[:, 0],
                       'x2': X[:, 1],
                       'x3': X[:, 2],
                       'x4': X[:, 3],
                       'y': y} )


"""# 2. Анализ данных"""

# 7-point summary
data0.describe()
#std -мера того, насколько значения в наборе данных рассеяны
#относительно среднего арифметического. Показывает, насколько типичные значения отклоняются от среднего
#mean — сумма всех значений в выборке, делённая на их количество. Используется для определения центральной тенденции в наборе данных

import seaborn
seaborn.boxplot( data0['x1'])

seaborn.boxplot( data0['x2'])

seaborn.boxplot( data0['x3'])

seaborn.boxplot( data0['x4'])

seaborn.boxplot( data0['y'])

seaborn.violinplot( data0['x1'])

seaborn.violinplot( data0['x2'])

seaborn.violinplot( data0['x3'])

seaborn.violinplot( data0['x4'])

seaborn.violinplot( data0['y'])

seaborn.histplot( data0['x1'])

seaborn.histplot( data0['x2'])

seaborn.histplot( data0['x3'])

seaborn.histplot( data0['x4'])

seaborn.histplot( data0['y'])

data0.corr()

seaborn.heatmap(data0.corr(), annot = True)

seaborn.pairplot( data0 )

# seaborn.boxplot( data0['x2'])
import plotly.express as px

px.box( data0['x1'] )

px.histogram ( data0['x1'] )

px.violin ( data0['x1'] )

"""# 3. Обучение модели"""

from sklearn.model_selection import train_test_split

train, test = train_test_split( data0, shuffle=True, random_state=0, test_size=0.2 )



from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()

"""Уравнение линейной регрессии
"""

lin_reg.fit( train[ ['x1', 'x2', 'x3', 'x4' ] ], train['y'] )

lin_reg.coef_

lin_reg.intercept_

### бонус

# 4. Тест и трейн

y_pred_train = lin_reg.predict( train[ ['x1', 'x2', 'x3', 'x4' ] ] )
y_pred_test = lin_reg.predict( test[ ['x1', 'x2', 'x3', 'x4' ] ] )

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

print(f"{ mean_absolute_error(y_pred_train, train['y'])= }")
print(f"{ mean_squared_error( y_pred_train, train['y'])= }")
print(f"{ r2_score( y_pred_train, train['y'])= }")

print()
print(f"{ mean_absolute_error(y_pred_test, test['y'])= }")
print(f"{ mean_squared_error( y_pred_test, test['y'])= }")
print(f"{ r2_score( y_pred_test, test['y'])= }")

import joblib
# Сохраняем обученную модель в файл models/model.joblib
joblib.dump(lin_reg, "models/model.joblib")

